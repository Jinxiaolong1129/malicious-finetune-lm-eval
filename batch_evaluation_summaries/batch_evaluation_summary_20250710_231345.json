{
  "evaluation_time": "2025-07-10T23:13:45.066621",
  "config_file": "/data3/user/jin509/malicious-finetuning/experiments-sft_stage-back/lm_eval_model_configs_final-debug.json",
  "tasks": "humaneval",
  "num_gpus_per_task": 4,
  "tensor_parallel_size": 4,
  "environment_variables": {
    "HF_HOME": "/data3/user/jin509/new_hf_cache",
    "HF_DATASETS_CACHE": "/data3/user/jin509/new_hf_cache/datasets",
    "HUGGINGFACE_HUB_CACHE": "/data3/user/jin509/new_hf_cache",
    "HF_DATASETS_OFFLINE": "1",
    "TRANSFORMERS_OFFLINE": "1",
    "HF_HUB_OFFLINE": "1",
    "HF_HUB_DISABLE_TELEMETRY": "1",
    "HF_ALLOW_CODE_EVAL": "1",
    "TOKENIZERS_PARALLELISM": "false",
    "CUDA_LAUNCH_BLOCKING": "1",
    "VLLM_WORKER_MULTIPROC_METHOD": "spawn"
  },
  "total_experiments": 1,
  "pending_experiments": 1,
  "total_duration_seconds": 192.01315212249756,
  "total_duration_minutes": 3.200219202041626,
  "output_mode": "lora_directories",
  "scheduling_mode": "ray_auto_scheduling",
  "progress_file": "/data3/user/jin509/malicious-finetuning/experiments-sft_stage-back/lm_eval_model_configs_final_progress-debug.csv",
  "results_summary": {
    "successful": 1,
    "failed": 0,
    "success_rate": 100.0
  },
  "detailed_results": [
    {
      "experiment_name": "default_final",
      "lora_path": "/data3/user/jin509/malicious-finetuning/experiments-sft_stage-back/default/gsm8k-BeaverTails-p0.6/Llama-2-7b-chat-hf-lora-r64-e10-b8-data500-train_llama2_sys3-eval_llama2_sys3",
      "status": "completed",
      "start_time": "2025-07-10T23:10:38.820838",
      "end_time": "2025-07-10T23:13:45.042242",
      "duration": 186.22138929367065,
      "duration_minutes": 3.1036898215611775,
      "log_file": "/data3/user/jin509/malicious-finetuning/experiments-sft_stage-back/default/gsm8k-BeaverTails-p0.6/Llama-2-7b-chat-hf-lora-r64-e10-b8-data500-train_llama2_sys3-eval_llama2_sys3/log_lm_eval/default_final_humaneval_gpu4.log",
      "stdout": "|-----:|------|---|----:|---|-----:|\n|humaneval|      1|create_test|     0|pass@1|   |0.128|±  |0.0262|\n\n\n🎉 vLLM直接LoRA多任务评测流程完成！\n✅ 成功评测了 1 个任务\n⚡ 效率提升: 无需合并权重，直接使用vLLM LoRA支持\n📁 结果文件保存在: /data3/user/jin509/malicious-finetuning/experiments-sft_stage-back/default/gsm8k-BeaverTails-p0.6/Llama-2-7b-chat-hf-lora-r64-e10-b8-data500-train_llama2_sys3-eval_llama2_sys3\nERROR 07-10 23:13:42 multiproc_worker_utils.py:120] Worker VllmWorkerProcess pid 914625 died, exit code: -15\n/home/jin509/anaconda3/envs/malicious_finetune/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 3 leaked semaphore objects to clean up at shutdown\n  warnings.warn('resource_tracker: There appear to be %d '\n/home/jin509/anaconda3/envs/malicious_finetune/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 1 leaked shared_memory objects to clean up at shutdown\n  warnings.warn('resource_tracker: There appear to be %d '\n",
      "stderr": "",
      "base_model": "/data3/user/jin509/hf_cache/hub/models--meta-llama--Llama-2-7b-chat-hf/snapshots/f5db02db724555f92da89c216ac04704f23d4590/",
      "tasks": "humaneval",
      "worker_pid": "910784",
      "gpu_id": "0",
      "num_gpus_used": 4,
      "visible_gpus": [
        "7",
        "5",
        "4",
        "6"
      ],
      "tensor_parallel_size": 4,
      "error_message": ""
    }
  ]
}